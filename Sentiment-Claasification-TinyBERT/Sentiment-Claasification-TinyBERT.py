# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: -all
#     custom_cell_magics: kql
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.11.2
#   kernelspec:
#     display_name: mlops-basic
#     language: python
#     name: python3
# ---

# %%
## ê°€ìƒí™˜ê²½
# !pip install pandas datasets

# %%
## ë°ì´í„° ë¡œë“œ

import pandas as pd

data = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Dataset.csv')

data.head()


# %%
from datasets import Dataset
dataset = Dataset.from_pandas(data)
dataset = dataset.train_test_split(test_size=0.3)
dataset

# %%
label2id = {'negative': 0, 'positive': 1}

dataset = dataset.map(lambda x: {'label': label2id[x['sentiment']]})

# %%
# ë°ì´í„°ì…‹ì„ ì €ì¥ -> Tokenization(í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
# !pip install transformers torch

# %%
from transformers import AutoTokenizer
import torch

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# Hugging Faceì˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©. TinyBERT ëª¨ë¸ì„ ì‚¬ìš©
model = 'huawei-noah/TinyBERT_General_4L_312D'

tokenizer = AutoTokenizer.from_pretrained(model, use_fast=True)
tokenizer

# %%
tokenizer(dataset['train'][0]['review'])

# %%
tokenizer('Today is monday')


# %%
def tokenize(batch):
    temp = tokenizer(batch['review'], padding=True, truncation=True, max_length=300)
    return temp

dataset = dataset.map(tokenize, batched=True, batch_size=None)


# %%
dataset['train'][0]

# %%
# Model Build
# https://huggingface.co/docs/transformers/v4.42.0/en/tasks/sequence_classification#evaluate
# !pip install evaluate accelerate scikit-learn

# %%
import evaluate
import numpy as np

accuracy = evaluate.load('accuracy')

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1) # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ë ˆì´ë¸” ë°ì´í„°ë¥¼ íŠœí”Œë¡œ ì…ë ¥

    return accuracy.compute(predictions=predictions, references=labels)


# %%
# !pip install tf-keras

# %%
from transformers import AutoModelForSequenceClassification

label2id = { 'negative': 0, 'positive': 1 }
id2label = {0: 'negative', 1: 'positive'}

model = AutoModelForSequenceClassification.from_pretrained(
    model,
    num_labels=len(label2id),
    label2id=label2id,
    id2label=id2label
)

# %%
from transformers import TrainingArguments, Trainer

# ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ì„¤ì • ì •ì˜
args = TrainingArguments(
    output_dir='train_dir',               # í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í„°ë¦¬
    overwrite_output_dir=True,            # ì¶œë ¥ ë””ë ‰í„°ë¦¬ì— ì´ë¯¸ ìˆëŠ” íŒŒì¼ì„ ë®ì–´ì“¸ì§€ ì—¬ë¶€
    num_train_epochs=3,                   # í•™ìŠµí•  ì—í¬í¬(epoch) ìˆ˜
    learning_rate=2e-5,                   # í•™ìŠµë¥  (learning rate)
    per_device_train_batch_size=32,       # ê° ë””ë°”ì´ìŠ¤(ì˜ˆ: GPU)ë‹¹ í•™ìŠµ ë°°ì¹˜ í¬ê¸°
    per_device_eval_batch_size=32,        # ê° ë””ë°”ì´ìŠ¤ë‹¹ í‰ê°€ ë°°ì¹˜ í¬ê¸°
    evaluation_strategy='epoch'           # í‰ê°€ ì „ëµ (ì—¬ê¸°ì„œëŠ” ë§¤ ì—í¬í¬ë§ˆë‹¤ í‰ê°€)
)

# Trainer ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ í•™ìŠµ ë° í‰ê°€ë¥¼ ê´€ë¦¬
trainer = Trainer(
    model=model,                          # í•™ìŠµí•  ëª¨ë¸
    args=args,                            # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
    train_dataset=dataset['train'],       # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹
    eval_dataset=dataset['test'],         # í‰ê°€ì— ì‚¬ìš©í•  ë°ì´í„°ì…‹
    compute_metrics=compute_metrics,      # í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    tokenizer=tokenizer                   # í† í¬ë‚˜ì´ì € (í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬)
)

# %%
trainer.train()

# %%
trainer.evaluate()

# %%
trainer.save_model('tinybert-sentiment-analysis')

# %%
from transformers import pipeline

device = 0 if torch.cuda.is_available() else -1

classifier = pipeline('text-classification', model='tinybert-sentiment-analysis', device=device)

# %%
data = [
    "The Chinese WW2 spy thriller â€œDecodedâ€ stands out for a number of reasons, mostly in spite of its conventional and hackneyed depiction of a troubled mathematician who deciphers encrypted messages for the mainland army. For starters, â€œDecodedâ€ provides a dramatic change of pace for two marquee-worthy names: soft-spoken heart-throb Liu Haoran, who takes an unusual leading man role as the gifted, but painfully shy codebreaker Rong Jinzhen; and director Chen Sicheng, whoâ€™s best known for his goofy mega-blockbuster â€œDetective Chinatownâ€ comedies. With â€œDecoded,â€ a plodding adaptation of Mai Jiaâ€™s popular source novel, Chen and Liu abandon cheap-seats humorâ€”Liu co-starred in the â€œDetective Chinatownâ€ movies, playing a straight man to comedian Wang Baoqiangâ€”to pursue a more sober, but less convincing type of cornball power fantasy.",
    "Liu also played a frustrated, but superhumanly gifted wallflower in â€œDetective Chinatown.â€ He was more convincing in those movies, partly because he was part of a winning buddy duo, but also because he wasnâ€™t trying to capital-A act while wearing hairpieces, whose synthetic hairs thin at an alarming rate as his character ages. As Jinzhen, Liu brings to mind Russell Croweâ€™s performance as the schizophrenic mathematician John Nash in â€œA Beautiful Mind.â€ That association gets harder and harder to shake as Jinzhen inevitably loses his grip on reality while trying to solve the Black Cipher, a nigh-impossible encryption key that was specifically designed to stump Jinzhen.",
    "Liuâ€™s mostly compelling as a leading man whenever he can suggest a lot about Jinzhen by speaking softly and deferring his gaze, as if Jinzhen expects to be reprimanded or inconvenienced at any time. Heâ€™s still often eclipsed by co-star John Cusack, whose broad and twitchy performance often distracts from his dialogue, as well as a series of campy dream sequences that ostensibly speak for Liuâ€™s introverted protagonist.",
    "Liu doesnâ€™t exactly light up the screen in his limited capacity as a humanoid plot device. His character either reacts to or follows after whatever promising new development might help Jinzhen to solve the latest problem thatâ€™s vexing him. The filmmakers do what they can to compensate for their unlikely heroâ€™s prevailing lack of charm and agency, but not even the combined forces of Lloyd Dobler and the Fab Four can bring a spike of joy to this DOA period drama."
]

classifier(data)

# %%
data=[
    """When are you guys going to fix all the issues?? Firstly, none of the reaction emojis are showing up. It's just a grey circle. When scrolling, it doesn't move freely. There's like a delay!! Very frustrating!!! Also, nearly every post is either from a "suggested page" or a "sponsered page". I hardly ever see anything from the pages that I actually follow or my friends pages. No wonder so many people are leaving FB ğŸ™„ğŸ™„"""
]

classifier(data)

# í”„ë¡œê·¸ë¨: êµ¬ê¸€ í”Œë ˆì´ ìŠ¤í† ì–´ ë§í¬ë¥¼ ë„£ìœ¼ë©´ => ë¦¬ë·° ë°ì´í„° ì „ì²´ í¬ë¡¤ë§ => ë¶€ì •ì˜ ê°•ë„ê°€ 0.8 ì´ìƒì¸ ì˜ê²¬ë§Œ í•„í„° ê±¸ì–´ì„œ ê³ ê°ì‚¬ì—ê²Œ ê³µìœ 
# ë³„1ê°œì— ë„¤ê±°í‹°ë¸Œ 0.8ì´ìƒ => slack ìœ¼ë¡œ ì•Œë¦¼ë³´ë‚´ => ëŒ€ì‘

# %%
# ëª¨ë¸ì„ s3ì— ì—…ë¡œë“œ
# (1) AWS ë¡œê·¸ì¸ í•œ ë‹¤ìŒ => ë²„í‚· ìƒì„±
# (2) boto3ë¥¼ í™œìš©í•´ì„œ ì½”ë“œ ë² ì´ìŠ¤ s3 ìƒì„± ë° íŒŒì¼ ì—…ë¡œë“œ
# !pip install boto3

# %%
import boto3

s3 = boto3.client('s3') # s3 ë§Œë“¤ ìˆ˜ ìˆëŠ” ê¶Œí•œ / ê³„ì •(aws credentials)

# s3.list_buckets()
# s3.create_bucket()

# ì–´ë–¤ ì›ë¦¬ë¡œ ì‹¤í–‰ì´ ë˜ëŠ” ê±¸ê¹Œìš”?

# aws credentials
# aws configure list

# %% [markdown]
# (1) IAM ê³„ì • ìƒì„±
# (2) AWS CLI ëª…ë ¹ì–´ ì„¤ì¹˜
# https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
#
# > aws version
# > aws configure
# ```
# 1. AW Acc k : [YourAWSAccessKeyHere]
# 2. AW Secret acc K :[YourAWSSecretKeyHere]
# Default region name :  [YourAWSregionHere]
# Default output format [json]: json
# ```
# > aws confiure list

# %%
# S3 ë²„í‚· ìƒì„±
import boto3
import time
from botocore.exceptions import ClientError

s3 = boto3.client('s3') # s3 ì½˜ì†”ì— ì ‘ì†
bucket_name = 'inseop-mlmodels' # bucket name

def create_bucket(bucket_name):
    response = s3.list_buckets()

    bucket_list = []
    for buck in response['Buckets']:
        bucket_list.append(buck['Name'])

    if bucket_name not in bucket_list:
        try:
            s3.create_bucket(
                Bucket=bucket_name,
                CreateBucketConfiguration={'LocationConstraint':'ap-northeast-2'}
            )
        except ClientError as e:
            print('ì˜¤ë¥˜ ë°œìƒ :', e)

            if e.response['Error']['Code'] == 'BucketAlreadyExists':    
                print('ë‹¤ë¥¸ ë²„í‚· ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.')

            elif e.reponse['Error']['Code'] == 'BucketAlreadyOwnedByYou':
                print('ì´ë¯¸ ë§Œë“¤ì–´ ì ¸ìˆëŠ” ë²„í‚·ì…ë‹ˆë‹¤.')
                
            else:
                print('ë²„í‚· ë§Œë“¤ê¸°ë¥¼ ì¬ì‹œë„ ì¤‘ì…ë‹ˆë‹¤.')
                time.sleep(3)
                create_bucket(bucket_name)


# %%
create_bucket('inseop-mlmodelss')

# %%
# DE => ë°ì´í„°ê°€ ìœ ì‹¤ë˜ì—ˆì„ ë•Œ ì–´ë–»ê²Œ ë³µêµ¬í•  ê²ƒì¸ê°€
# AB180 => ë§¨ë‚  ë³µêµ¬. ë”ë¯¸ ë°ì´í„°ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ => ë‹¤ì‹œ ì¬ê°€ê³µ => ë‹¤ì‹œ DB insert
# í•˜ë£¨, í•œì‹œê°„

# %% [markdown]
# S3ì— íŒŒì¼(í´ë”) ì—…ë¡œë“œ

# %%
import boto3

s3 = boto3.client('s3')
bucket_name = 'inseop-mlmodels'

s3.upload_file

# %%
import os

for root, dir, files in os.walk('tinybert-sentiment-analysis'):
    # print(root, dir, files)

    for file_name in files:
        # print(file_name)

        file_path = os.path.join(root, file_name)
        print(file_path)
    
        # s3.upload_file(file_path, bucket_name, file_name)
        s3.upload_file(file_path, bucket_name, file_path)

# %%
import os

def s3_upload_file_folder_name(model_folder, folder_name):
    for root, dir, files in os.walk(model_folder):
        for file_name in files:
            file_path = os.path.join(root, file_name)
            s3_key = os.path.join(folder_name, file_name)
            s3.upload_file(file_path, bucket_name, s3_key)
            # EC2ì—ë‹¤ê°€ docker => EC2 - AWS CLI(credentialsì€ í•„ìš”X) + Docker pull


# %%
s3_upload_file_folder_name('tinybert-sentiment-analysis', 'tinybert-test-folder')
